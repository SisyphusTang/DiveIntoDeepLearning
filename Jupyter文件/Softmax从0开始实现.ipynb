{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch包和d2l包默认安装在了d2l包下面\n",
    "import torch\n",
    "from IPython import display\n",
    "from d2l import torch as d2l\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "os.environ [\"KMP_DUPLICATE_LIB_OK\"] =\"TRUE\"\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "# torchvision 包含一些计算机视觉的相关库 transfrom包含图像处理的一些算法\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "batch_size = 256\n",
    "def get_dataloader_workers():  #@save\n",
    "    \"\"\"使用4个进程来读取数据\"\"\"\n",
    "    return 4\n",
    "\n",
    "# 这里数据提前下好了 只需要读取本地文件即可\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"T://ProgramsData//data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"T://ProgramsData//data\", train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=get_dataloader_workers()),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=get_dataloader_workers()))\n",
    "\n",
    "\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784 \n",
    "# 十个类别\n",
    "num_outputs = 10\n",
    "# 权重正态分布初始化 784 * 10\n",
    "W = torch.normal(0,0.01,size=(num_inputs,num_outputs),requires_grad=True)\n",
    "# 偏置\n",
    "b = torch.zeros(num_outputs,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1,keepdim=True)\n",
    "    return X_exp / partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3935, 0.1623, 0.1716, 0.0743, 0.1983],\n",
       "         [0.0528, 0.0068, 0.1162, 0.0676, 0.7566]]),\n",
       " tensor([1.0000, 1.0000]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.normal(0,1,(2,5))\n",
    "X_prob = softmax(X)\n",
    "X_prob,X_prob.sum(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1,W.shape[0])),W) + b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.5000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([0,2])\n",
    "y_hat = torch.tensor([[0.1,0.3,0.6],[0.3,0.2,0.5]])\n",
    "# [0,1]为行索引，y为列索引，y_hat是一个新张量\n",
    "y_hat[[0,1],y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_hat为对应的预测概率值 yi当中有一个为1 其余为0\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)),y])\n",
    "\n",
    "cross_entropy(y_hat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "t = torch.normal(0,1,(2,5))\n",
    "print(len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回数据\n",
    "def accuracy(y_hat,y):\n",
    "    # 二维张量且第二维分类>1 取概率最大的那个\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis = 1)\n",
    "    # cmp是一个bool数组 y_hat预测值和实际值y相同是true\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat, y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulator类对多个变量进行累加\n",
    "class Accumulator:\n",
    "    def __init__(self,n):\n",
    "        self.data = [0.0] * n\n",
    "    \n",
    "    # 将传入的参数和累加器当中的数据逐个对应相加\n",
    "    def add(self,*args):\n",
    "        self.data = [a + float(b) for a,b in zip(self.data,args)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "    \n",
    "    def _getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):\n",
    "    # 评价任意模型net精度\n",
    "    # 判断net是不是moudle的实例 pt当中的神经网络基类\n",
    "    if isinstance(net,torch.nn.Module):\n",
    "        # 进入评估模式 梯度不会被计算\n",
    "        net.eval()\n",
    "    # 正确预测数 和 预测总数累加\n",
    "    metric = Accumulator(2)\n",
    "    # 接下来的代码不需要计算梯度 节省内存加快计算\n",
    "    with torch.no_grad():\n",
    "        # X 输入特征 y真实标签\n",
    "        for X,y in data_iter:\n",
    "            # 将准确率accuracy(net(X),y) 与 样本数量y.numel加到累加器中\n",
    "            # y.numel返回y当中的数量\n",
    "            metric.add(accuracy(net(X),y),y.numel())\n",
    "    # 整个数据集上的准确率 正确预测数 / 预测种数\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
