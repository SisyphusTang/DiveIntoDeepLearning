{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9183bba",
   "metadata": {},
   "source": [
    "## 1 标量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142077e",
   "metadata": {},
   "source": [
    "数学上的常量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d778772",
   "metadata": {},
   "source": [
    "## 2 向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc163ff",
   "metadata": {},
   "source": [
    "多个标量有序排列，排成一列为列向量，排成一行为行向量。机器学习当中默认是列向量，\n",
    "由于表示等问题，一般写成行向量的转置形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1df2784",
   "metadata": {},
   "source": [
    "## 3 矩阵\n",
    "多个行向量/列向量构成的矩阵，也称之为张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20142b",
   "metadata": {},
   "source": [
    "## 4 一些计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404194b",
   "metadata": {},
   "source": [
    "### 4.1 矩阵元素对应位置相乘，作为对应位置的结果\n",
    "称之为Hadamard积\n",
    "![](https://raw.githubusercontent.com/SisyphusTang/Picture-bed/master/image-20230716214556820.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73fbaf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2., 2.],\n",
       "         [2., 2., 2.]]),\n",
       " tensor([[2., 2., 2.],\n",
       "         [2., 2., 2.]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.ones(2,3)\n",
    "B = torch.ones(2,3)\n",
    "A *= 2\n",
    "B *= 2\n",
    "A,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7646e6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4.],\n",
       "        [4., 4., 4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df7331",
   "metadata": {},
   "source": [
    "### 4.2 降维"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf142f60",
   "metadata": {},
   "source": [
    "让矩阵沿着某一轴进行求和，结果这一轴就被消除掉了，以达到降维的作用。\n",
    "当然，**也可以让原数组的维度不发生变化，只要在后面加上keepdims=True即可。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00af49b",
   "metadata": {},
   "source": [
    "### 4.3 点积（Dot Product）\n",
    "这里不介绍向量与向量、矩阵与向量，直接介绍矩阵与矩阵的点积。\n",
    "![](https://raw.githubusercontent.com/SisyphusTang/Picture-bed/master/image-20230716215341521.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a7f49",
   "metadata": {},
   "source": [
    "矩阵A的行乘以矩阵B的列的和作为对应位置的值。\n",
    "![](https://raw.githubusercontent.com/SisyphusTang/Picture-bed/master/image-20230716215651950.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03165d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12.],\n",
       "        [12., 12.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.ones(3,2)\n",
    "B *= 2\n",
    "torch.mm(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8dae10",
   "metadata": {},
   "source": [
    "### 4.4 范数（新接触的概念）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0108d2d0",
   "metadata": {},
   "source": [
    "#### L1范数与L2范数\n",
    "简单来说，L1范数就是向量所有元素的绝对值求和，L2范数是所有元素的平方和开根号。\n",
    "公式如下：\n",
    "![](https://raw.githubusercontent.com/SisyphusTang/Picture-bed/master/image-20230716220036126.png)\n",
    "![](https://raw.githubusercontent.com/SisyphusTang/Picture-bed/master/image-20230716220102179.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2b08ec",
   "metadata": {},
   "source": [
    "#### 矩阵的Frobenius范数 是矩阵元素平方和的平方根\n",
    "![](https://raw.githubusercontent.com/SisyphusTang/Picture-bed/master/image-20230716220236568.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06489325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8990)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵A的L1范数\n",
    "t = torch.abs(A).sum()\n",
    "t\n",
    "# 矩阵A的L2范数\n",
    "t = torch.norm(A)\n",
    "t\n",
    "# 矩阵的Frobenius范数\n",
    "t = torch.norm(A)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e6140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
