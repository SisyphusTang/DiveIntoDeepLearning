{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 读写文件\n",
    "+ 有时我们希望保存训练的模型， 以备将来在各种环境中使用（比如在部署中进行预测）\n",
    "+ 当运行一个耗时较长的训练过程时， 最佳的做法是定期保存中间结果， 以确保在服务器电源被不小心断掉时，我们不会损失几天的计算结果。\n",
    "\n",
    "总结:\n",
    "+ 1. 可以通过`load()`和`save()`来进行单个张量的保存\n",
    "+ 2. 可以通过`save(net.state_dict(),'filename') ` `load_state_dict('filename')`进行整个模型参数的保存与读取"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.1 加载和保存张量\n",
    "单个张量直接调用load和save函数分别读写，两个函数都需要我们提供一个名称？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "# x作为输出保存到x-file文件当中\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 存储在文件中的数据读回内存\n",
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储一个张量列表 然后读回内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.arange(4)\n",
    "torch.save([x,y],'./data/x-files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 读取张量列表\n",
    "x2,y2 = torch.load('./data/x-files')\n",
    "print(x2)\n",
    "print(y2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "写入或读取字符串映射到张量的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0, 1, 2, 3])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x':x,'y':y}\n",
    "torch.save(mydict,'./data/mydict')\n",
    "mydict2 = torch.load('./data/mydict')\n",
    "mydict2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5.2 加载和保存模型的参数\n",
    "深度学习框架提供了内置函数来保存和加载整个网络，但是保存仅仅保存参数而不是整个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden.weight', tensor([[-0.0672,  0.0381,  0.0085,  ...,  0.0638,  0.1145, -0.0556],\n",
      "        [-0.1977, -0.0807,  0.0423,  ..., -0.2199,  0.2040, -0.0379],\n",
      "        [ 0.1484,  0.0889, -0.0906,  ..., -0.2149,  0.0583, -0.1980],\n",
      "        ...,\n",
      "        [-0.1278,  0.0878,  0.2043,  ..., -0.0130,  0.2119, -0.0305],\n",
      "        [-0.1637, -0.0405,  0.1935,  ..., -0.0667,  0.1848,  0.0622],\n",
      "        [ 0.2220,  0.0347, -0.0784,  ...,  0.0210,  0.0171, -0.1268]])), ('hidden.bias', tensor([ 0.0749,  0.0924, -0.1360, -0.2092, -0.0994,  0.1444, -0.1062,  0.1258,\n",
      "        -0.0841,  0.1795, -0.0471,  0.1253,  0.0656, -0.1549, -0.1015, -0.1067,\n",
      "        -0.2080, -0.1775, -0.0849,  0.0214, -0.1719, -0.1077,  0.1326,  0.2154,\n",
      "         0.2005, -0.0488,  0.1414,  0.2168, -0.1023,  0.0573, -0.0811,  0.0504,\n",
      "        -0.1227, -0.1026, -0.1160, -0.2156, -0.0480,  0.2084, -0.0152, -0.1541,\n",
      "         0.0188, -0.0053, -0.0516, -0.1625,  0.0876,  0.1302,  0.0270,  0.0454,\n",
      "         0.0189, -0.1782, -0.1707, -0.0004,  0.1222, -0.1914, -0.0735, -0.2118,\n",
      "        -0.0006,  0.1818,  0.0704,  0.1690,  0.2209,  0.1379, -0.0482,  0.1329,\n",
      "         0.0628, -0.1313,  0.0385, -0.1613,  0.1006,  0.1739,  0.0560,  0.0782,\n",
      "         0.0843,  0.1156, -0.1521,  0.1721,  0.1785,  0.0103,  0.1498,  0.0309,\n",
      "         0.0855, -0.0672, -0.0702,  0.1908, -0.1993,  0.2206,  0.1471, -0.1174,\n",
      "         0.0673, -0.0716,  0.0227, -0.1627, -0.2228,  0.0060, -0.1679, -0.0205,\n",
      "         0.0993,  0.1992, -0.0183, -0.0964,  0.0265,  0.0211, -0.1920, -0.0933,\n",
      "         0.1512,  0.2080,  0.1393, -0.0812,  0.1631, -0.1672,  0.0430, -0.0761,\n",
      "        -0.1480, -0.1323, -0.1967,  0.1371, -0.2127,  0.1548,  0.2065,  0.2148,\n",
      "        -0.1232,  0.1002,  0.2219, -0.0904, -0.0268, -0.0195, -0.0500,  0.1147,\n",
      "         0.0661, -0.1130,  0.0825, -0.1979,  0.0026, -0.2000, -0.1244,  0.0232,\n",
      "        -0.2052,  0.0693,  0.0132,  0.2197, -0.1864, -0.0342,  0.1610, -0.1936,\n",
      "         0.0996,  0.1592,  0.1736,  0.1252, -0.1521, -0.0959,  0.0877,  0.1228,\n",
      "        -0.2128,  0.1682, -0.0677, -0.0441,  0.1390, -0.0565,  0.1960,  0.0902,\n",
      "         0.0745,  0.1848, -0.0655,  0.2210, -0.1651,  0.0884,  0.1273,  0.0365,\n",
      "        -0.2099,  0.1895,  0.0186, -0.0594,  0.1227, -0.1693,  0.1438, -0.1177,\n",
      "        -0.2224,  0.0042,  0.1528,  0.2194,  0.0782,  0.0366,  0.0180,  0.0233,\n",
      "         0.1902, -0.2218,  0.0993,  0.1495, -0.0791,  0.0821,  0.1248,  0.0360,\n",
      "        -0.1308,  0.2227, -0.0174, -0.1025, -0.1410, -0.1155,  0.1476,  0.1094,\n",
      "         0.1551, -0.1379,  0.1792,  0.0320, -0.0079,  0.1415,  0.1068, -0.0551,\n",
      "        -0.1278, -0.2073,  0.2052, -0.0296,  0.0402,  0.0009,  0.1092,  0.0909,\n",
      "        -0.1158,  0.1022, -0.1382,  0.0810,  0.0364,  0.1800, -0.2142,  0.1333,\n",
      "         0.0568,  0.1370, -0.0259, -0.1909,  0.0188,  0.1031, -0.2051,  0.1206,\n",
      "        -0.1351, -0.0105,  0.1100,  0.1168, -0.1378, -0.0178,  0.1614, -0.1040,\n",
      "         0.0093, -0.1502, -0.1207, -0.2214,  0.0391, -0.2020,  0.2027,  0.0974,\n",
      "         0.0762, -0.0037,  0.1770, -0.0893, -0.0255,  0.0970, -0.0027,  0.1823])), ('output.weight', tensor([[ 0.0049,  0.0442,  0.0524,  ...,  0.0359, -0.0157, -0.0281],\n",
      "        [-0.0142,  0.0438, -0.0034,  ...,  0.0489,  0.0190,  0.0394],\n",
      "        [ 0.0323, -0.0338,  0.0554,  ...,  0.0281, -0.0164,  0.0469],\n",
      "        ...,\n",
      "        [-0.0084,  0.0112,  0.0405,  ..., -0.0303,  0.0350, -0.0255],\n",
      "        [ 0.0617,  0.0149,  0.0284,  ...,  0.0146, -0.0051, -0.0534],\n",
      "        [ 0.0389, -0.0250, -0.0243,  ...,  0.0405,  0.0444,  0.0509]])), ('output.bias', tensor([ 0.0088,  0.0553,  0.0596,  0.0424,  0.0445,  0.0190, -0.0480, -0.0500,\n",
      "         0.0539,  0.0396]))])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型的参数存储在一个叫做“mlp.params”的文件中\n",
    "torch.save(net.state_dict(),'./data/mpl.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "# 从文件当中加载参数\n",
    "clone.load_state_dict(torch.load('./data/mpl.params'))\n",
    "# 设置模型为评估模式 关闭一些计算 更快速更稳定\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_jupyter",
   "language": "python",
   "name": "demo_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
